// SPDX-FileCopyrightText: 2025 SAP SE or an SAP affiliate company and Gardener contributors
//
// SPDX-License-Identifier: Apache-2.0

package service

import (
	"context"
	"fmt"
	commonconstants "github.com/gardener/scaling-advisor/api/common/constants"
	commontypes "github.com/gardener/scaling-advisor/api/common/types"
	sacorev1alpha1 "github.com/gardener/scaling-advisor/api/core/v1alpha1"
	mkapi "github.com/gardener/scaling-advisor/api/minkapi"
	corev1 "k8s.io/api/core/v1"
	nodev1 "k8s.io/api/node/v1"
	schedulingv1 "k8s.io/api/scheduling/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/client-go/tools/events"
	"sync/atomic"
	"time"
)

const (
	// ProgramName is the program name for the scaling advisor service.
	ProgramName = "scadsvc"
)

// ActivityStatus represents the operational status of an activity
type ActivityStatus string

const (
	ActivityStatusPending ActivityStatus = "Pending"
	ActivityStatusRunning ActivityStatus = "Running"
	ActivityStatusSuccess ActivityStatus = metav1.StatusSuccess
	ActivityStatusFailure ActivityStatus = metav1.StatusFailure
)

// ScalingAdviceRequest encapsulates the request parameters for generating scaling advice.
type ScalingAdviceRequest struct {
	ScalingAdviceRequestRef
	// Constraint is the cluster scaling constraint using which the scaling advice is generated.
	Constraint sacorev1alpha1.ClusterScalingConstraint
	// Snapshot is the snapshot of the resources in the cluster at the time of the request.
	Snapshot *ClusterSnapshot
	// Feedback captures feedback from the consumer of the scaling advice, which can be used to improve future scaling advice generation.
	Feedback *sacorev1alpha1.ClusterScalingFeedback
	// EnableDiagnostics indicates whether diagnostics should be enabled for the scaling advice generation.
	// If it is enabled then it will populate ScalingAdviceResponse.ScalingAdvice.Status.Diagnostic field.
	EnableDiagnostics bool
}

type ScalingAdviceRequestRef struct {
	// ID is the Request unique identifier for which this response is generated.
	ID string
	// CorrelationID is the correlation identifier for the request, used to correlate this response with the request.
	CorrelationID string
}

// ScalingAdviceResponse encapsulates the response from the scaling advisor service.
type ScalingAdviceResponse struct {
	RequestRef ScalingAdviceRequestRef
	// Message is a human-readable message providing additional context about the response.
	Message string
	// ScalingAdvice contains the scaling advice generated by the scaling advisor service.
	ScalingAdvice *sacorev1alpha1.ClusterScalingAdvice
}

// ScalingAdvisorServiceConfig holds the configuration for the scaling advisor service.
type ScalingAdvisorServiceConfig struct {
	// ScalingAdvisorService also offers a HTTP server endpoint for scaling advice requests/responses
	commontypes.ServerConfig
	// MinKAPIConfig holds the configuration for the MinKAPI server used by the scaling advisor service.
	MinKAPIConfig mkapi.Config
	commontypes.QPSBurst
	// CloudProvider is the cloud provider for which the scaling advisor service is initialized.
	CloudProvider commontypes.CloudProvider
	// MaxParallelSimulations is the maximum number of parallel simulations that can be run by the scaling advisor service.
	MaxParallelSimulations int
}

// ScalingAdviceResponseFn is a callback function which is invoked by the scaling advisor service when generating scaling advice.
// The callback maybe invoked zero or more times during the generation of scaling advice with callbackType representing the type of change in the scaling advice.
type ScalingAdviceResponseFn func(response ScalingAdviceResponse) error

// ScalingAdviceEvent represents a single event emitted by the ScalingAdvisorService
// during the generation of scaling advice.
//
// Each event will contain either a Response or an Err:
//
//   - If Response is non-nil, it contains one piece of scaling advice.
//   - If Err is non-nil, it represents a terminal error that occurred during
//     advice generation. No further events will be sent after an error event.
//
// The caller should treat the channel of ScalingAdviceEvent as a stream of
// responses that may end either because the service has finished generating
// advice or because an error was encountered. The stream ends when the channel
// is closed.
//
// Usage:
//
//	events := svc.GenerateAdvice(ctx, req)
//	for ev := range events {
//	    if ev.Err != nil {
//	        log.Printf("advice generation failed: %v", ev.Err)
//	        break
//	    }
//	    process(ev.Response)
//	}
//
// If the provided context is canceled, the service should stop generation and
// close the channel.
type ScalingAdviceEvent struct {
	// Response contains a piece of scaling advice generated by the service.
	// It is non-nil only when Err is nil.
	Response *ScalingAdviceResponse

	// Err contains a fatal error that occurred during generation.
	// It is non-nil only when Response is nil.
	Err error
}

// ScalingAdvisorService is the high-level facade for the scaling advisor service.
type ScalingAdvisorService interface {
	commontypes.Service
	// GenerateAdvice begins generating scaling advice for the given request.
	//
	// It returns a channel of ScalingAdviceEvent values. The channel will be closed
	// when advice generation is completed or a fatal error has occurred.
	//
	// The caller must consume all events from the channel until it is closed to
	// avoid leaking goroutines inside the service implementation.
	//
	// The provided context can be used to cancel generation prematurely. In this
	// case, the channel will be closed without further events.
	GenerateAdvice(ctx context.Context, req ScalingAdviceRequest) <-chan ScalingAdviceEvent
}

// App represents an application process that wraps a ScalingAdvisorService, , an application context and application cancel func.
// `main` entry-point functions that embed scadsvc are expected to construct a new App instance via cli.LaunchApp and shutdown applications via cli.ShutdownApp
type App struct {
	Service ScalingAdvisorService
	Ctx     context.Context
	Cancel  context.CancelFunc
}

// SchedulerLaunchParams holds the parameters required to launch a kube-scheduler instance.
type SchedulerLaunchParams struct {
	commontypes.ClientFacades
	// EventSink is the event sink used to send events from the kube-scheduler.
	EventSink events.EventSink
}

// SchedulerLauncher defines the interface for launching a kube-scheduler instance.
// There will be a limited number of kube-scheduler instances that can be launched at a time.
type SchedulerLauncher interface {
	// Launch launches and runs an embedded scheduler instance asynchronously.
	// If the limit of running schedulers is reached, it will block.
	// An error is returned if the scheduler fails to start.
	Launch(ctx context.Context, params *SchedulerLaunchParams) (SchedulerHandle, error)
}

// SchedulerHandle defines the interface for managing a kube-scheduler instance.
type SchedulerHandle interface {
	// Stop stops the scheduler instance.
	Stop()
	// GetParams returns the parameters used to launch the scheduler instance.
	GetParams() SchedulerLaunchParams
}

// ClusterSnapshot represents a snapshot of the cluster at a specific time and encapsulates the scheduling relevant information required by the kube-scheduler.
// Pods inside the ClusterSnapshot should not have SchedulingGates - these should be filtered out by creator of the ClusterSnapshot.
type ClusterSnapshot struct {
	// Pods are the pods that are present in the cluster.
	Pods []PodInfo
	// Nodes are the nodes that are present in the cluster.
	Nodes []NodeInfo
	// PriorityClasses are the priority classes that are present in the cluster.
	PriorityClasses []schedulingv1.PriorityClass
	// RuntimeClasses are the runtime classes that are present in the cluster.
	RuntimeClasses []nodev1.RuntimeClass
}

func (c *ClusterSnapshot) GetUnscheduledPods() []PodInfo {
	var unscheduledPods []PodInfo
	for _, pod := range c.Pods {
		if pod.NodeName == "" {
			unscheduledPods = append(unscheduledPods, pod)
		}
	}
	return unscheduledPods
}

func (c *ClusterSnapshot) GetNodeCountByPlacement() (map[sacorev1alpha1.NodePlacement]int, error) {
	nodeCountByPlacement := make(map[sacorev1alpha1.NodePlacement]int)
	for _, nodeInfo := range c.Nodes {
		p, err := getNodePlacement(nodeInfo)
		if err != nil {
			return nil, err
		}
		nodeCountByPlacement[p]++
	}
	return nodeCountByPlacement, nil
}

func getNodePlacement(nodeInfo NodeInfo) (placement sacorev1alpha1.NodePlacement, err error) {
	nodeTemplateName, ok := nodeInfo.Labels[commonconstants.LabelNodeTemplateName]
	if !ok {
		err = fmt.Errorf("%w: %s", ErrMissingRequiredLabel, commonconstants.LabelNodeTemplateName)
		return
	}
	nodePoolName, ok := nodeInfo.Labels[commonconstants.LabelNodePoolName]
	if !ok {
		err = fmt.Errorf("%w: %s", ErrMissingRequiredLabel, commonconstants.LabelNodePoolName)
		return
	}
	region, ok := nodeInfo.Labels[corev1.LabelTopologyRegion]
	if !ok {
		err = fmt.Errorf("%w: %s", ErrMissingRequiredLabel, corev1.LabelTopologyRegion)
		return
	}
	az, ok := nodeInfo.Labels[corev1.LabelTopologyZone]
	if !ok {
		err = fmt.Errorf("%w: %s", ErrMissingRequiredLabel, corev1.LabelTopologyZone)
		return
	}
	placement = sacorev1alpha1.NodePlacement{
		NodePoolName:     nodePoolName,
		NodeTemplateName: nodeTemplateName,
		InstanceType:     nodeInfo.InstanceType,
		Region:           region,
		AvailabilityZone: az,
	}
	return
}

// PodInfo contains the minimum set of information about corev1.Pod that will be required by the kube-scheduler.
// NOTES:
//  1. PodSchedulingGates should not be not part of PodInfo. It is expected that pods having scheduling gates will be filtered out before setting up simulation runs.
//  2. Consider including PodSpec.Resources in future when it graduates to beta/GA.
type PodInfo struct {
	ResourceMeta
	// AggregatedRequests is an aggregated resource requests for all containers of the Pod.
	AggregatedRequests map[corev1.ResourceName]int64
	// Volumes are the volumes that are attached to the Pod.
	Volumes []corev1.Volume `json:"volumes"`
	// NodeSelector is the node selector for the Pod.
	NodeSelector map[string]string
	// NodeName is the name of the node where the Pod is scheduled.
	NodeName string
	// Affinity is the affinity rules for the Pod.
	Affinity *corev1.Affinity
	// SchedulerName is the name of the scheduler that should be used to schedule the Pod.
	SchedulerName string
	// Tolerations are the tolerations for the Pod.
	Tolerations []corev1.Toleration
	// PriorityClassName is the name of the priority class that should be used to schedule the Pod.
	PriorityClassName         string
	Priority                  *int32
	PreemptionPolicy          *corev1.PreemptionPolicy
	RuntimeClassName          *string
	Overhead                  map[corev1.ResourceName]int64
	TopologySpreadConstraints []corev1.TopologySpreadConstraint
	ResourceClaims            []corev1.PodResourceClaim
}

func (p *PodInfo) GetResourceInfo() PodResourceInfo {
	return PodResourceInfo{
		UID:                p.UID,
		NamespacedName:     p.NamespacedName,
		AggregatedRequests: p.AggregatedRequests,
	}
}

// NodeInfo contains the minimum set of information about corev1.Node that will be required by the kube-scheduler.
type NodeInfo struct {
	ResourceMeta
	// InstanceType is the instance type for the Node.
	InstanceType string
	// Unschedulable indicates whether the node is unschedulable.
	Unschedulable bool
	// Taints are the node's taints.
	Taints []corev1.Taint
	// Capacity is the total resource capacity of the node.
	Capacity map[corev1.ResourceName]int64
	// Allocatable is the allocatable resource capacity of the node.
	Allocatable map[corev1.ResourceName]int64
	// Conditions are the node's conditions.
	Conditions []corev1.NodeCondition
	// CSIDriverVolumeMaximums is a map of CSI driver names to the maximum number of unique volumes managed by the
	// CSI driver that can be used on a node.
	CSIDriverVolumeMaximums map[string]int32
}

func (n *NodeInfo) GetResourceInfo() NodeResourceInfo {
	return NodeResourceInfo{
		Name:         n.Name,
		InstanceType: n.InstanceType,
		Capacity:     n.Capacity,
		Allocatable:  n.Allocatable,
	}
}

type ResourceMeta struct {
	// UID is the unique identifier for the resource.
	UID types.UID
	types.NamespacedName
	// Labels are the labels associated with the resource.
	Labels map[string]string
	// Annotations are the annotations associated with the resource.
	Annotations map[string]string
	// DeletionTimestamp is the timestamp when the resource deletion was triggered.
	DeletionTimestamp time.Time
	// OwnerReferences are the owner references associated with the resource.
	OwnerReferences []metav1.OwnerReference
}

type InstancePriceInfo struct {
	InstanceType string  `json:"instancetype"`
	Region       string  `json:"region"`
	VCPU         int32   `json:"VCPU"`
	Memory       float64 `json:"memory"`
	HourlyPrice  float64 `json:"hourlyPrice"`
	OS           string  `json:"os"`
}

// PriceKey represents the key for a instance type price within a cloud provider.
type PriceKey struct {
	Name   string
	Region string
}
type InstancePricingAccess interface {
	// GetInfo gets the InstancePriceInfo (whicn includes price) for the given region and instance type.
	// TODO: should we also pass OS name here ? if so, we need to need to change ClusterScalingConstraint.
	GetInfo(region, instanceTypeName string) (InstancePriceInfo, error)
}
type GetProviderInstancePricingAccessFunc func(provider commontypes.CloudProvider, instanceTypeInfoPath string) (InstancePricingAccess, error)

type NodeScorer interface {
	// Compute computes the node score given the NodeScoreArgs. On failure, it must return an error with the sentinel error api.ErrComputeNodeScore
	Compute(args NodeScoreArgs) (NodeScore, error)
}
type NodeScoreArgs struct {
	// ID that must be given to the NodeScore produced by the NodeScorer
	ID string
	// Placement represents the placement information for the Node.
	Placement sacorev1alpha1.NodePlacement
	// ScaledAssignment represents the assignment of the scaled Node for the current run.
	ScaledAssignment *NodePodAssignment
	// OtherAssignments represent the assignment of unscheduled Pods to either an existing Node which is part of the ClusterSnapshot
	// or it is a winning simulated Node from a previous run.
	OtherAssignments []NodePodAssignment
	// UnscheduledPods is the slice of unscheduled pods that remain unscheduled after simulation is completed.
	UnscheduledPods []types.NamespacedName
}

// NodeScore to be documented later.
type NodeScore struct {
	// ID uniquely identifies this NodeScore
	ID string
	// Placement represents the placement information for the Node.
	Placement       sacorev1alpha1.NodePlacement
	UnscheduledPods []types.NamespacedName
	// Value is the score value for this Node.
	Value              int
	ScaledNodeResource NodeResourceInfo
}

type GetWeightsFunc func(instanceType string) (map[corev1.ResourceName]float64, error)
type GetNodeScorer func(scoringStrategy commontypes.NodeScoringStrategy, instanceTypeInfoAccess InstancePricingAccess, weightsFn GetWeightsFunc) (NodeScorer, error)
type GetNodeScoreSelector func(scoringStrategy commontypes.NodeScoringStrategy) (NodeScoreSelector, error)

type PodResourceInfo struct {
	UID types.UID
	types.NamespacedName
	// AggregatedRequests is an aggregated resource requests for all containers of the Pod.
	AggregatedRequests map[corev1.ResourceName]int64
}

// NodeResourceInfo represents the subset of NodeInfo such that NodeScorer can compute an effective NodeScore.
// TODO think of a better name.
type NodeResourceInfo struct {
	Name         string
	InstanceType string
	// Capacity is the total resource capacity of the node.
	Capacity map[corev1.ResourceName]int64
	// Allocatable is the allocatable resource capacity of the node.
	Allocatable map[corev1.ResourceName]int64
}

type NodePodAssignment struct {
	Node          NodeResourceInfo
	ScheduledPods []PodResourceInfo
}

// NodeScoreSelector selects the winning NodeScore amongst the NodeScores of a given simulation pass and returns the pointer to the same.
// If there is no winning node score amongst the group, then it returns nil.
type NodeScoreSelector func(groupNodeScores []NodeScore, weightsFn GetWeightsFunc, pricing InstancePricingAccess) (winningNodeScore *NodeScore, err error)

// Simulation represents an activity that performs valid unscheduled pod to ready node assignments on a minkapi View.
// A simulation implementation may use a k8s scheduler - either embedded or external to do this, or it may form a SAT/MIP model
// from the pod/node data and run a tool that solves the model.
type Simulation interface {
	// Name returns the logical simulation name
	Name() string
	// ActivityStatus returns the current ActivityStatus of the simulation
	ActivityStatus() ActivityStatus
	// NodePool returns the target node pool against which the simulation should be run
	NodePool() *sacorev1alpha1.NodePool
	// NodeTemplate returns the target node template against which the simulation should be run
	NodeTemplate() *sacorev1alpha1.NodeTemplate
	// Run executes the simulation to completion and returns any encountered error. This is a blocking call and callers are
	// expected to manage concurrency and SimRunResult consumption.
	Run(ctx context.Context) error
	// Result returns the latest SimRunResult if the simulation is in ActivityStatusSuccess,
	// or nil if the simulation is in ActivityStatusPending or ActivityStatusRunning
	// or an error if the ActivityStatus is ActivityStatusFailure
	Result() (SimRunResult, error)
}

type SimRunResult struct {
	// Name of the Simulation that produced this result.
	Name string
	// ScaledNode is the simulated scaled node.
	ScaledNode *corev1.Node
	NodeScoreArgs
}

// SimulationArgs represents the argument necessary for creating a simulation instance.
type SimulationArgs struct {
	NodePool            *sacorev1alpha1.NodePool
	AvailabilityZone    string
	NodeTemplateName    string
	GroupRunPassCounter *atomic.Uint32
	SchedulerLauncher   SchedulerLauncher
	View                mkapi.View
	// TrackPollInterval is the polling interval for tracking pod scheduling in the view and reconciling simulation state
	TrackPollInterval time.Duration
	// Timeout is the simulation timeout
	Timeout time.Duration
}

// CreateSimulationFunc is a factory function for constructing a simulation instance
type CreateSimulationFunc func(name string, args *SimulationArgs) (Simulation, error)

// SimulationGroup is a group of simulations at the same priority level (ie a partition of simulations). We attempt to run simulations for the
// given group and get a preferred NodeScore for simulations belonging to a group before moving to the group at the
// next priority.
//
//	Example:1
//		np-a: 1 {nt-a: 1, nt-b: 2, nt-c: 1}
//		np-b: 2 {nt-q: 2, nt-r: 1, nt-s: 1}
//
//		p1: {PoolPriority: 1, NTPriority: 1, nt-a, nt-c}
//		p2: {PoolPriority: 1, NTPriority: 2, nt-b}
//		p3: {PoolPriority: 2, NTPriority: 1, nt-r, nt-s}
//		p4: {PoolPriority: 2, NTPriority: 2, nt-q}
//
//	Example:2
//		np-a: 1 {nt-a: 1, nt-b: 2, nt-c: 1}
//		np-b: 2 {nt-q: 2, nt-r: 1, nt-s: 1}
//		np-c: 1 {nt-x: 2, nt-y: 1}
//
//		p1: {PoolPriority: 1, NTPriority: 1, nt-a, nt-c, nt-y}
//		p2: {PoolPriority: 1, NTPriority: 2, nt-b, nt-x}
//		p3: {PoolPriority: 2, NTPriority: 1, nt-r, nt-s}
//		p4: {PoolPriority: 2, NTPriority: 2, nt-q}
type SimulationGroup interface {
	Name() string
	GetKey() SimGroupKey
	GetSimulations() []Simulation
	Run(ctx context.Context) (SimGroupRunResult, error)
}

// CreateSimulationGroupsFunc represents a factory function for partitioning Simulation instances into one or more SimulationGroups
type CreateSimulationGroupsFunc func(simulations []Simulation) ([]SimulationGroup, error)

// SimGroupKey represents the key for a SimulationGroup.
type SimGroupKey struct {
	NodePoolPriority     int32
	NodeTemplatePriority int32
}

func (k SimGroupKey) String() string {
	return fmt.Sprintf("(%d:%d)", k.NodePoolPriority, k.NodeTemplatePriority)
}

type SimGroupRunResult struct {
	// Name of the group that produced this result.
	Name string
	// Key is the simulation group key (partition key)
	Key               SimGroupKey
	SimulationResults []SimRunResult
}

// SimGroupScores represents the scoring results for the simulation group after running the NodeScorer against the SimGroupRunResult.
type SimGroupScores struct {
	AllNodeScores   []NodeScore
	WinnerNodeScore *NodeScore
	WinnerNode      *corev1.Node
}
